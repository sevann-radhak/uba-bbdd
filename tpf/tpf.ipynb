{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Universidad de Buenos Aires.</h1>\n",
    "<h4 align=\"center\">Trabajo práctico integrador. \n",
    "<br> Bases de Datos para Inteligencia Artificial.</h4>\n",
    "<p align=\"right\"> Por: Sevann Radhak Triztan. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-** Parámetros de conexión a la base de datos.  \n",
    "**-** Funciones de inicialización y conexión.  \n",
    "**-** Creación de la base de datos, sus tablas, columnas y relaciones.  \n",
    "**-** Inserción de datos.  \n",
    "**-** Se eliminarn registros defectuosos (con referencias o llaves inexistentes.)  \n",
    "**Consultas.**  \n",
    "**1.** Colores más utilizados en los 90.  \n",
    "**2.** Colores únicos.  \n",
    "**3.** Tendencia de piezas por sets a lo largo de los años.  \n",
    "**4.** Temáticas más populares de los 2000.  \n",
    "**Observaciones.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql, connect, extensions\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parámetros de conexión a la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PARAMS = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"<<password>>\",\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"postgres\"  \n",
    "}\n",
    "\n",
    "DB_NAME = \"lego_database\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones de inicialización y conexión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def database_exists(conn, db_name):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT 1 FROM pg_database WHERE datname=%s\", (db_name,))\n",
    "        return cur.fetchone() is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql_from_file(conn, file_path, **kwargs):\n",
    "    with open(file_path, 'r') as file:\n",
    "        sql = file.read().format(**kwargs)\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(connection_params, db_name):\n",
    "    try:        \n",
    "        conn = psycopg2.connect(**connection_params)\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT 1 FROM pg_database WHERE datname = %s\", (db_name,))\n",
    "            exists = cur.fetchone()\n",
    "            if exists:\n",
    "                print(f\"Database '{db_name}' already exists.\")\n",
    "            else:\n",
    "                cur.execute(f\"CREATE DATABASE {db_name}\")                \n",
    "                print(f\"Database '{db_name}' created successfully.\")\n",
    "            DB_PARAMS[\"database\"] = db_name\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while creating the database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(db_params):\n",
    "    sql_files = [\n",
    "    'create_colors_table.sql',\n",
    "    'create_part_categories_table.sql',\n",
    "    'create_parts_table.sql',\n",
    "    'create_themes_table.sql',\n",
    "    'create_sets_table.sql',\n",
    "    'create_inventories_table.sql',\n",
    "    'create_inventory_parts_table.sql',\n",
    "    'create_inventory_sets_table.sql'\n",
    "]\n",
    "\n",
    "    try:\n",
    "        with psycopg2.connect(**db_params) as conn:\n",
    "            conn.set_session(autocommit=True)\n",
    "            \n",
    "            for sql_file in sql_files:\n",
    "                execute_sql_from_file(conn, f'sql/{sql_file}')\n",
    "                print(f\"Table from '{sql_file}' created.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating tables: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de la base de datos, sus tablas, columnas y relaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'lego_database' already exists.\n"
     ]
    }
   ],
   "source": [
    "create_database(DB_PARAMS, DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table from 'create_colors_table.sql' created.\n",
      "Table from 'create_part_categories_table.sql' created.\n",
      "Table from 'create_parts_table.sql' created.\n",
      "Table from 'create_themes_table.sql' created.\n",
      "Table from 'create_sets_table.sql' created.\n",
      "Table from 'create_inventories_table.sql' created.\n",
      "Table from 'create_inventory_parts_table.sql' created.\n",
      "Table from 'create_inventory_sets_table.sql' created.\n"
     ]
    }
   ],
   "source": [
    "create_tables(DB_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserción de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_from_csv_to_db(db_params, file_path, table_name):\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        columns = next(reader)  \n",
    "        records = [[None if item == '' else item for item in row] for row in reader] \n",
    "        \n",
    "        conn = connect(**db_params)\n",
    "        conn.set_isolation_level(extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        placeholders = ', '.join(['%s'] * len(columns))  \n",
    "        all_placeholders = ', '.join([f\"({placeholders})\"] * len(records))  \n",
    "        query = sql.SQL(\"INSERT INTO {table} ({fields}) VALUES {values} ON CONFLICT DO NOTHING\").format(\n",
    "            table=sql.Identifier(table_name),\n",
    "            fields=sql.SQL(', ').join(map(sql.Identifier, columns)),\n",
    "            values=sql.SQL(all_placeholders)\n",
    "        )\n",
    "\n",
    "        flat_records = [item for sublist in records for item in sublist]  \n",
    "\n",
    "        try:\n",
    "            cursor.execute(query, flat_records)\n",
    "            print(\"All records inserted successfully.\")\n",
    "        except psycopg2.IntegrityError as e:\n",
    "            if \"violates foreign key constraint\" in str(e):\n",
    "                missing_part_num = str(e).split(\"Key (part_num)=(\")[1].split(\")\")[0]\n",
    "                print(f\"Error: part_num {missing_part_num} is not present in the 'parts' table.\")\n",
    "            else:\n",
    "                print(f\"Error executing the query: {e}\")\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(f\"Error executing the query: {error}\")\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(db_params, query, params=None):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(**db_params)\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        if params:\n",
    "            cursor.execute(query, params)\n",
    "        else:\n",
    "            cursor.execute(query)\n",
    "        \n",
    "        if query.strip().lower().startswith((\"select\", \"with\")):\n",
    "            records = cursor.fetchall()\n",
    "            return records\n",
    "        else:\n",
    "            conn.commit()\n",
    "            print(\"Query executed successfully.\")\n",
    "            return None\n",
    "        \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(f\"Error executing the query: {error}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los registros insertados exitosamente.\n",
      "Conexión cerrada.\n"
     ]
    }
   ],
   "source": [
    "table = 'colors'\n",
    "insert_data_from_csv_to_db(DB_PARAMS, f'./raw/{table}.csv', table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los registros insertados exitosamente.\n",
      "Conexión cerrada.\n"
     ]
    }
   ],
   "source": [
    "table = 'part_categories'\n",
    "insert_data_from_csv_to_db(DB_PARAMS, f'./raw/{table}.csv', table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los registros insertados exitosamente.\n",
      "Conexión cerrada.\n"
     ]
    }
   ],
   "source": [
    "table = 'themes'\n",
    "insert_data_from_csv_to_db(DB_PARAMS, f'./raw/{table}.csv', table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los registros insertados exitosamente.\n",
      "Conexión cerrada.\n"
     ]
    }
   ],
   "source": [
    "table = 'parts'\n",
    "insert_data_from_csv_to_db(DB_PARAMS, f'./raw/{table}.csv', table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los registros insertados exitosamente.\n",
      "Conexión cerrada.\n"
     ]
    }
   ],
   "source": [
    "table = 'sets'\n",
    "insert_data_from_csv_to_db(DB_PARAMS, f'./raw/{table}.csv', table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los registros insertados exitosamente.\n",
      "Conexión cerrada.\n"
     ]
    }
   ],
   "source": [
    "table = 'inventories'\n",
    "insert_data_from_csv_to_db(DB_PARAMS, f'./raw/{table}.csv', table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminarn registros defectuosos (con referencias o llaves inexistentes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT DISTINCT part_num FROM parts\"\n",
    "unique_part_nums =  execute_query(DB_PARAMS, query)\n",
    "unique_part_nums = [part_num[0] for part_num in unique_part_nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File updated and _OLDER copy created.\n"
     ]
    }
   ],
   "source": [
    "table = 'inventory_parts'\n",
    "path = f'./raw/{table}.csv'\n",
    "\n",
    "shutil.copyfile(path, f'./raw/{table}_OLDER.csv')\n",
    "\n",
    "df_inventory_parts = pd.read_csv(path)\n",
    "df_to_keep = df_inventory_parts[df_inventory_parts['part_num'].isin(unique_part_nums)]\n",
    "df_to_keep.to_csv(path, index=False)\n",
    "\n",
    "print(\"File updated and _OLDER copy created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los registros insertados exitosamente.\n",
      "Conexión cerrada.\n"
     ]
    }
   ],
   "source": [
    "insert_data_from_csv_to_db(DB_PARAMS, f'./raw/{table}.csv', table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los registros insertados exitosamente.\n",
      "Conexión cerrada.\n"
     ]
    }
   ],
   "source": [
    "table = 'inventory_sets'\n",
    "insert_data_from_csv_to_db(DB_PARAMS, f'./raw/{table}.csv', table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(result, column_names):\n",
    "    if result:\n",
    "        df = pd.DataFrame(result, columns=column_names)\n",
    "        print(df)\n",
    "    else:\n",
    "        print(\"No results were found or an error occurred.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.** Colores más utilizados en los 90.  \n",
    "Identifica cuáles son los 10 colores más frecuentemente usados en los sets de LEGO durante la década de los 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         color_name  total_quantity\n",
      "0             Black           61341\n",
      "1        Light Gray           36189\n",
      "2             White           32899\n",
      "3               Red           30469\n",
      "4            Yellow           25469\n",
      "5              Blue           19499\n",
      "6             Green            5437\n",
      "7         Dark Gray            5246\n",
      "8             Brown            3065\n",
      "9  Trans-Neon Green            1601\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT c.name AS color_name, SUM(ip.quantity) AS total_quantity\n",
    "    FROM sets s\n",
    "    JOIN inventories i ON s.set_num = i.set_num\n",
    "    JOIN inventory_parts ip ON i.id = ip.inventory_id\n",
    "    JOIN parts p ON ip.part_num = p.part_num\n",
    "    JOIN colors c ON ip.color_id = c.id\n",
    "    WHERE s.year BETWEEN 1990 AND 1999\n",
    "    GROUP BY c.name\n",
    "    ORDER BY total_quantity DESC\n",
    "    LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "result = execute_query(DB_PARAMS, query)\n",
    "column_names = ['color_name', 'total_quantity']\n",
    "show_result(result, column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.** Colores únicos.  \n",
    "Determina la cantidad de colores que son únicos en toda la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total\n",
      "0    135\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT COUNT(DISTINCT id) AS unique_colors\n",
    "    FROM colors;\n",
    "\"\"\"\n",
    "\n",
    "result = execute_query(DB_PARAMS, query)\n",
    "column_names = ['total']\n",
    "show_result(result, column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.** Tendencia de piezas por sets a lo largo de los años.  \n",
    "Analiza cómo ha evolucionado la cantidad de piezas incluidas en los sets de LEGO a través del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year         avg_num_parts prev_year_avg_num_parts   diff_from_prev_year\n",
      "0   1950   10.1428571428571429                    None                  None\n",
      "1   1953   16.5000000000000000     10.1428571428571429    6.3571428571428571\n",
      "2   1954   12.3571428571428571     16.5000000000000000   -4.1428571428571429\n",
      "3   1955   36.8571428571428571     12.3571428571428571   24.5000000000000000\n",
      "4   1956   18.5000000000000000     36.8571428571428571  -18.3571428571428571\n",
      "..   ...                   ...                     ...                   ...\n",
      "61  2013  181.3440134907251265    149.7658536585365854   31.5781598321885411\n",
      "62  2014  169.7152875175315568    181.3440134907251265  -11.6287259731935697\n",
      "63  2015  201.6691729323308271    169.7152875175315568   31.9538854147992703\n",
      "64  2016  253.0771812080536913    201.6691729323308271   51.4080082757228642\n",
      "65  2017  260.8209459459459459    253.0771812080536913    7.7437647378922546\n",
      "\n",
      "[66 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    WITH yearly_avg_parts AS (\n",
    "        SELECT s.year, AVG(s.num_parts) AS avg_num_parts\n",
    "        FROM sets s\n",
    "        GROUP BY s.year\n",
    "        ORDER BY s.year\n",
    "    )\n",
    "    SELECT \n",
    "        year,\n",
    "        avg_num_parts,\n",
    "        LAG(avg_num_parts, 1) OVER (ORDER BY year) AS prev_year_avg_num_parts,\n",
    "        avg_num_parts - LAG(avg_num_parts, 1) OVER (ORDER BY year) AS diff_from_prev_year\n",
    "    FROM yearly_avg_parts;\n",
    "\"\"\"\n",
    "\n",
    "result = execute_query(DB_PARAMS, query)\n",
    "column_names = ['year', 'avg_num_parts', 'prev_year_avg_num_parts', 'diff_from_prev_year']    \n",
    "\n",
    "show_result(result, column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.** Temáticas más populares de los 2000.  \n",
    "Identifica cuáles fueron las temáticas de sets más populares durante la década de los 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                theme_name  total_sets\n",
      "0                     City         142\n",
      "1              Bulk Bricks         124\n",
      "2                Basic Set         121\n",
      "3                  Creator         118\n",
      "4                  Clikits         105\n",
      "5                  Technic         104\n",
      "6  Star Wars Episode 4/5/6          88\n",
      "7                   Soccer          80\n",
      "8             Supplemental          73\n",
      "9       Knights Kingdom II          69\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT \n",
    "        t.name AS theme_name,\n",
    "        COUNT(s.set_num) AS total_sets\n",
    "    FROM \n",
    "        sets s\n",
    "    JOIN \n",
    "        themes t ON s.theme_id = t.id\n",
    "    WHERE \n",
    "        s.year BETWEEN 2000 AND 2009\n",
    "    GROUP BY \n",
    "        t.name\n",
    "    ORDER BY \n",
    "        total_sets DESC\n",
    "    LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "result = execute_query(DB_PARAMS, query)\n",
    "column_names = ['theme_name', 'total_sets']    \n",
    "\n",
    "show_result(result, column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observaciones.  \n",
    "- **Manejo de Valores Nulos en themes:**  \n",
    "Se reemplazaron las cadenas vacías por None en la columna correspondiente a tipo entero en la tabla themes. Esta modificación fue necesaria para asegurar que los inserts se ejecutaran correctamente sin errores de tipo.  \n",
    "\n",
    "- **Actualización de Registros en inventory_parts:**\n",
    "Se añadió la cláusula ON CONFLICT (pk_column) DO UPDATE SET en la inserción de inventory_parts para manejar conflictos por claves primarias duplicadas. Esto permite que los registros existentes sean actualizados automáticamente en caso de conflicto.\n",
    "\n",
    "- **Proceso de Validación de IDs en inventory_parts:**  \n",
    "Se implementó un proceso para verificar la existencia de los IDs en la tabla parts. Este proceso compara los registros de inventory_parts y elimina aquellos que apuntan a IDs inexistentes en parts. Además, se creó una copia de seguridad del archivo antes de proceder con la eliminación y la inserción de registros.  \n",
    "\n",
    "-  **Estado de Otras Tablas:**  \n",
    "No se presentaron problemas adicionales con otras tablas, y los procesos de inserción y actualización se realizaron sin inconvenientes.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
